{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM5pt/urxExcxQ1JPoIZwVV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fobo/COSC-480/blob/main/COSC480_final_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "KSr8nopdjg0c",
        "outputId": "985cb86c-182e-4258-c4b2-283c23e48ecf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Total sequences: 178204, Players with sequences: 1014\n",
            "Total sequences: 45979, Players with sequences: 254\n",
            "Epoch 0, Train Loss: 0.0074, Validation Loss: 0.0075\n",
            "Epoch 1, Train Loss: 0.0073, Validation Loss: 0.0075\n",
            "Epoch 2, Train Loss: 0.0073, Validation Loss: 0.0076\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ef7d50b4ff2e>\u001b[0m in \u001b[0;36m<cell line: 108>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-ef7d50b4ff2e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhn\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1123\u001b[0;31m             result = _VF.lstm(\n\u001b[0m\u001b[1;32m   1124\u001b[0m                 \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m                 \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/fobo/COSC-480/refs/heads/main/baseballdata.csv\"\n",
        "\n",
        "# Load data directly from GitHub raw URL\n",
        "data = pd.read_csv(url)\n",
        "# Normalize features\n",
        "scalers = {col: MinMaxScaler() for col in data.columns[2:]}\n",
        "for col, scaler in scalers.items():\n",
        "    data[col] = scaler.fit_transform(data[[col]])\n",
        "\n",
        "# Split data using the new function\n",
        "def split_train_test_by_player(data, test_size=0.2, random_state=42):\n",
        "    unique_players = data[\"Player\"].unique()\n",
        "    train_players, test_players = train_test_split(unique_players, test_size=test_size, random_state=random_state)\n",
        "    train_data = data[data[\"Player\"].isin(train_players)]\n",
        "    test_data = data[data[\"Player\"].isin(test_players)]\n",
        "    return train_data, test_data\n",
        "\n",
        "train_data, test_data = split_train_test_by_player(data)\n",
        "\n",
        "# Create sequences\n",
        "def create_sequences(data, sequence_length=5):\n",
        "    sequences, targets = [], []\n",
        "    player_seq_map = {}\n",
        "    for player, group in data.groupby('Player'):\n",
        "        group = group.sort_values('Date')\n",
        "        features = group.iloc[:, 2:-1].values\n",
        "        target = group['fantasy_points'].values\n",
        "        player_sequences = []\n",
        "        for i in range(len(features) - sequence_length):\n",
        "            seq = features[i:i+sequence_length]\n",
        "            tgt = target[i+sequence_length]\n",
        "            sequences.append(seq)\n",
        "            targets.append(tgt)\n",
        "            player_sequences.append((seq, tgt))\n",
        "        player_seq_map[player] = player_sequences\n",
        "    print(f\"Total sequences: {len(sequences)}, Players with sequences: {len(player_seq_map)}\")\n",
        "    return sequences, targets, player_seq_map\n",
        "\n",
        "train_sequences, train_targets, train_player_map = create_sequences(train_data)\n",
        "test_sequences, test_targets, test_player_map = create_sequences(test_data)\n",
        "\n",
        "class FantasyDataset(Dataset):\n",
        "    def __init__(self, sequences, targets):\n",
        "        self.sequences = sequences\n",
        "        self.targets = targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.sequences[idx], self.targets[idx]\n",
        "\n",
        "def collate_fn(batch):\n",
        "    sequences, targets = zip(*batch)\n",
        "    padded_sequences = torch.nn.utils.rnn.pad_sequence(\n",
        "        [torch.tensor(seq, dtype=torch.float32) for seq in sequences],\n",
        "        batch_first=True\n",
        "    )\n",
        "    targets = torch.tensor(targets, dtype=torch.float32)\n",
        "    return padded_sequences, targets\n",
        "\n",
        "train_dataset = FantasyDataset(train_sequences, train_targets)\n",
        "test_dataset = FantasyDataset(test_sequences, test_targets)\n",
        "\n",
        "class FantasyLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
        "        super(FantasyLSTM, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, (hn, _) = self.lstm(x)\n",
        "        out = self.fc(hn[-1])\n",
        "        return out\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = len(data.columns) - 3  # Exclude Player, Date, and fantasy_points\n",
        "hidden_size = 64  # Increased hidden size\n",
        "output_size = 1\n",
        "num_layers = 3  # Increased number of layers\n",
        "lr = 0.001\n",
        "epochs = 10  # Increased number of epochs\n",
        "\n",
        "model = FantasyLSTM(input_size, hidden_size, output_size, num_layers).to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=lr)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    for sequences, targets in train_loader:\n",
        "        sequences = sequences.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        predictions = model(sequences)\n",
        "        loss = criterion(predictions.squeeze(), targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    if epoch % 1 == 0:\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for sequences, targets in test_loader:\n",
        "                sequences = sequences.to(device)\n",
        "                targets = targets.to(device)\n",
        "\n",
        "                predictions = model(sequences)\n",
        "                loss = criterion(predictions.squeeze(), targets)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch}, Train Loss: {train_loss/len(train_loader):.4f}, Validation Loss: {val_loss/len(test_loader):.4f}\")\n",
        "\n",
        "\n",
        "# Function to calculate moving average\n",
        "def moving_average(values, window_size):\n",
        "    return np.convolve(values, np.ones(window_size), 'valid') / window_size\n",
        "\n",
        "# Function to select three random players from the test set and plot predictions vs. actual\n",
        "def plot_predictions(model, test_loader, scalers, test_data, save_path=\"results\", num_players=3, window_size=10):\n",
        "    model.eval()\n",
        "    player_predictions = {player: {'actual': [], 'predicted': []} for player in test_data['Player'].unique()}\n",
        "\n",
        "    idx = 0\n",
        "    with torch.no_grad():\n",
        "        for sequences, targets in test_loader:\n",
        "            sequences = sequences.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            outputs = model(sequences)\n",
        "            outputs = scalers['fantasy_points'].inverse_transform(outputs.cpu().numpy().reshape(-1, 1)).flatten()\n",
        "            targets = scalers['fantasy_points'].inverse_transform(targets.cpu().numpy().reshape(-1, 1)).flatten()\n",
        "\n",
        "            for i in range(len(outputs)):\n",
        "                player_name = test_data['Player'].iloc[idx + i]\n",
        "                player_predictions[player_name]['actual'].append(targets[i])\n",
        "                player_predictions[player_name]['predicted'].append(outputs[i])\n",
        "            idx += len(outputs)\n",
        "\n",
        "    # Filter out players with no games\n",
        "    filtered_players = {player: preds for player, preds in player_predictions.items() if preds['actual']}\n",
        "\n",
        "    if not filtered_players:\n",
        "        print(\"No players with available data for testing.\")\n",
        "        return\n",
        "\n",
        "    selected_players = random.sample(list(filtered_players.keys()), min(num_players, len(filtered_players)))\n",
        "\n",
        "    # Print actual and predicted values for selected players\n",
        "    for player in selected_players:\n",
        "        actual = filtered_players[player]['actual']\n",
        "        predicted = filtered_players[player]['predicted']\n",
        "        print(f\"\\nPlayer: {player}, Number of Games: {len(actual)}\")\n",
        "        print(f\"{'Game':>5} {'Actual':>10} {'Predicted':>15}\")\n",
        "        print(\"-\" * 30)\n",
        "        for i, (a, p) in enumerate(zip(actual, predicted)):\n",
        "            print(f\"{i+1:>5} {a:>10.2f} {p:>15.2f}\")\n",
        "\n",
        "    # Plot predictions for selected players with moving average\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    for player in selected_players:\n",
        "        actual = filtered_players[player]['actual']\n",
        "        predicted = filtered_players[player]['predicted']\n",
        "        smoothed_actual = moving_average(actual, window_size)\n",
        "        smoothed_predicted = moving_average(predicted, window_size)\n",
        "        plt.plot(smoothed_actual, label=f\"{player} - Actual (Smoothed)\", linestyle='-', marker='o')\n",
        "        plt.plot(smoothed_predicted, label=f\"{player} - Predicted (Smoothed)\", linestyle='--', marker='x')\n",
        "\n",
        "    plt.xlabel(\"Game Index (Smoothed)\")\n",
        "    plt.ylabel(\"Fantasy Points\")\n",
        "    plt.title(\"Fantasy Points Prediction for Selected Players (Smoothed)\")\n",
        "    plt.legend()\n",
        "\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "    filename = os.path.join(save_path, \"fantasy_points_prediction.png\")\n",
        "    plt.savefig(filename)\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"Plot saved to {filename}\")\n",
        "\n",
        "# Plot predictions for three random players with moving average\n",
        "plot_predictions(model, test_loader, scalers, test_data)\n"
      ]
    }
  ]
}